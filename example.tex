\section{Loop-Free}
\label{sec:example}

\subsection{Example}

\begin{figure}[t!]
\label{fig:example}
\includegraphics[width=3in]{figures/noloops.png}
\caption{Running example, discussed in Section \ref{sec:example}.}
\end{figure}

Applying routing updates in a way that guarantees no loops is a basic but already interesting consistency property. Consider the five node example network with a single destination $d$ in Figure \ref{fig:example}. The existing routing to destination $d$ on the left of the figure should be updated according to the right of the figure. A naive way to update is to simply send out the forwarding updates (e.g., ``node $u$: for destination $d$ send to $x$''). However, when doing so, it might happen that node $x$ updates its rule before node $y$, introducing a routing loop between nodes $x$ and $y$. This loop will eventually disappear, namely once node $y$ updates its rule, but in an asynchronous system it is difficult to give guarantees when this will happen.

At the other end of the spectrum, the SDN controller could first (i) distribute the new rules, then (ii) wait for an acknowledgement of all the nodes that they have received the new rules, then (iii) tell all the nodes to stop sending packets, and finally, once (iv) they all acknowledged that, (v) tell the nodes to now use the new rules. After the nodes (vi) acknowledge that they are using the new rules, the SDN controller can tell them to (vii) remove the old rules, as they are not needed anymore. This solution does not suffer from loops, as the old and the new solution are well-separated in time.\footnote{Strictly speaking, this protocol is not sufficient, as there might be packets in transit, still using the old rules when rushing through the protocol. Consider a packet sent from sent from $y$ to $x$ shortly before $y$ received the order to stop sending (iii). If node $x$ already passed the last step of the protocol when receiving the packet, node $x$ has not other option then sending the packet back to node $y$, i.e. the packet is experiencing a loop.} However, it is also terribly slow. One may speed up the process by omitting steps (iii) and (iv). Now, assuming that node $x$ received the command to use the new rule (v) earlier than node $y$. As such, in order to guarantee no loop between nodes $x$ and $y$, we must introduce version numbers in packets such that nodes $x$ and $y$ know that packets from $x$ respectively $y$ must be treated according to the new respectively old rules. This is the solution proposed by \ref{theoriginalprincetonpaper}.

One may ask whether version numbers are really necessary, just to guarantee no loops? Also, one may ask whether a faster solution is possible. What nodes are really dependent on each other? This may look like a technicality, but as we all know, nodes are often temporarily unavailable or reacting slowly. If a node must wait for another node, there should better be a consistency reason for it, and not merely protocol overhead. Is there something like a \emph{minimal protocol for a given consistency guarantee}? This is exactly the question we address in this paper.

Regarding our example, the answer to this question is quite simple. Node $u$ does not even need to change its rule, as it always just forwards to $x$, hence node $u$ does not even have to be informed about the rule changes. Node $v$ can switch immediately after being informed about the new rule, as no matter whether using the old or new rule, the packet will always end up at node $x$, with no possibility to experience a loop. Also node $y$ can switch immediately to the new rule, as its packet will then directly reach the destination node $d$. The only critical node in our example is node $x$, for which we understand that node $x$ must wait until node $y$ implemented the switch, as otherwise our network might experience a loop.

More generally, achieving loop-free consistency requires rule updates to wait for each other in a \emph{dependency tree}, i.e., a node may have to wait for one parent node having switched to the new rule before being able to switch itself. Let the destination $d$ be the root of the dependency tree.

We will show two solutions, one with advantages regarding practice as the parent in the dependency forest is always a neighbor node. The practical solution is provably fast, however, it is not optimal regarding dependencies. So, in addition, we also show a more theoretical solution, which (in polynomial time) can compute the minimal dependency forest, i.e. where nodes can switch to the new solution in minimal time.
A node $p$ is a parent of a child node $c$ in the dependency forest if $c$ points to $p$ according to the new rules, e.g. $x$ is a parent of $u$ and $v$. Now, starting at the root, nodes first switch to the new rule, and then inform all their children in the dependency tree to switch as well. Apart from the packets-in-transit problem described above, correctness is immediate: Nodes that are in the dependency tree of the destination will only switch to the new rule once all the nodes on the new path to the destination have already switched. Based on the discussion on the example, it is easy to see that this solution is not minimal, as node $v$ cannot switch immediately, after learning the new rule, but must wait on $x$.


\subsection{Minimal Protocol}

In the following, we will present a protocol which is minimal regarding its dependencies. As the example shows, there may other nodes that can switch immediately. As such the dependency tree turns into a \emph{dependency forest}. As before, in this dependency forest, parents will inform their children when it is safe to use the new rule. The only difference is that the dependency forest is cut to its bare minimum. For simplicity, we first describe the protocol as if there was just a single destination $d$. We then discuss the case where we have multiple destinations.

We need to define \emph{good} and \emph{bad} nodes as follows: The destination $d$ is by definition good. All other nodes $u$ are defined as good or bad regarding the node $v$ at the end of the new forwarding rule \texttt{u.new = v}. If all paths (mixing new and [TODO: still valid] old rules) of $v$ point to the same node $r$ (possibly $r = d$), without loop, then $u$ is good. Else ($v$ has a path that points into a loop) $u$ is bad.

[TODO: is there a framework for algorithms? maybe not... text version instead]

The algorithm to construct the dependency forest is as follows: Initially, we let all good nodes to be roots of the dependency forest. Then, iteratively, while not all nodes are processed, we process an arbitrary good node $u$ by removing its old rule. Removing $u$'s old rule might turn other nodes good; if $v$ turns good when processing $u$, then $v$ is a child of $u$ in the dependency forest.

[TODO: here the old psudo-code]

Algorithm:
All good nodes u have no parent in the virtual forest, i.e. u.parent = nil, good nodes are ready to be processed.
While not all nodes are processed
	Process an arbitrary good node u: remove the old pointer u.old
	For all bad nodes v:
		If processing u made v good, then v.parent = u

[TODO: Remark: This also works with more than two trees, i.e. with multiple versions of old trees and one new tree. Should I describe a more direct algorithm, an algorithm that does recognize good and bad without calling the Tarjan loop discovery subroutine? What about the failures? In several versions, what happens if a node just does not ack the changes of old versions? Will it become a leaf?]

Lemmas:

Lemma 1: A processed node remains good.

Proof: After node $u$ is processed, $u$ inherits all the properties from its new parent \texttt{u.new = v}. TODO: why not losing the property again? Just removing pointers? What about interior collection points r?

Lemma 2: Every node is eventually processed.

Proof: Take any unprocessed node. We follow its new pointer until we find a pair $u,v$ with \texttt{u.new = v}, $u$ is not yet processed, and $v$ is processed. Since the root of the new pointer in-tree is already processed at the start of the algorithm, and we started at an unprocessed node, such a pair must exist. Because of Lemma 1, $v$ is good, and as such $u$ can be processed.

Lemma 3: The process produces a virtual forest.

Proof: Originally good nodes are the roots of the virtual forest. If a node $u$ is processed later than a node $v$, then $v$ cannot point to $u$. Listing all the nodes in the order of processing as such only gives parent pointers in one direction, towards the past. As such the virtual forest does not have cycles.

Lemma 4: The process is correct/sufficient (no loops).

Proof: For the sake of contradiction, assume that there is a packet which is sent into a loop. The loop must consist of at least one new pointer, call that \texttt{u.new}. In other words, node $u$ in the loop deleted its old pointer because it was good. However, we know that \texttt{u.new} is part of a loop, in other words, we know that the algorithm made a mistake when it decided that $u$ should be good (last line of algorithm). (TODO: simplify)

Lemma 5: The process is optimal/necessary/minimal (no node could flip earlier).

Proof: If nodes can flip immediately, they are by definition optimal. So let us look instead at child node $c$, which must wait for parent $p$, i.e. \texttt{c.par = p}. Node $c$ becomes good once parent $p$ removes its old pointer, before node $c$ was bad. This means that \texttt{p.old} pointed to a loop, which was removed when \texttt{p.old} was removed. In other words, by definition node $c$ could not switch to the new pointer at any earlier stage, without risking sending a packet on exactly this loop.




