\begin{table*}[t!]
\begin{center}
\begin{small}
\begin{tabular}{>{\centering\arraybackslash}p{0.7in}|>{\centering\arraybackslash}m{0.75in}|>{\centering\arraybackslash}p{0.8in}|>{\centering\arraybackslash}p{0.85in}|>{\centering\arraybackslash}p{0.85in}|>{\centering\arraybackslash}p{0.75in}|}
&
  \textbf{None}
&
  \textbf{Self}
&
  \textbf{Downstream subset}
&
  \textbf{Downstream all}
&
  \textbf{Global}
\ \\ \hline

  \textbf{Eventual consistency}
&
  Always guaranteed
&
&
&
&
\ \\ \hline

  \textbf{Drop freedom}
&
  \multicolumn{1}{>{\columncolor[gray]{0.8}}c|}{Impossible}
&
  Add before remove
&
&
&
\ \\ \hline

  \textbf{Memory limit}
&
  \multicolumn{1}{>{\columncolor[gray]{0.8}}c|}{Impossible}
&
  Remove before add
&
&
&
\ \\ \hline

  \textbf{Loop freedom}
&
  \multicolumn{2}{>{\columncolor[gray]{0.8}}c|}{Impossible (Lemma \iflongversion \ref{lemma:imp loop-free} \else 6 \fi )}
&
  Rule dep. forest (\S\ref{sec:minimal})
&
  Rule dep. tree (\S\ref{sec:practical})
&
\ \\ \hline

  \textbf{Packet coherence}
&
  \multicolumn{3}{>{\columncolor[gray]{0.8}}c|}{Impossible (Lemma \iflongversion \ref{lemma:imp packet coherence} \else 7 \fi)}
&
  Per-flow ver. numbers
&
  Global ver. numbers~\cite{safeupdate}
\ \\ \hline

  \textbf{Bandwidth limit}
&
  \multicolumn{4}{>{\columncolor[gray]{0.8}}c|}{Impossible (Lemma  \iflongversion \ref{lemma:imp bandwidth limit} \else 8 \fi)}
&
  Staged partial moves~\cite{swan}
\ \\ \hline
\end{tabular}
\end{small}
\end{center}
\vspace{-10pt}
\caption{Some basic consistency properties (rows) and their dependencies (columns). Proofs of lemmas are in
\iflongversion
the Appendix.
\else
~\cite{tr}.
\fi
}
\label{tbl:big}
\end{table*}

\section{Consistency space}
\label{sec:table}

Thus far, we have focused on loop freedom; we now take a broader view of the range of consistency properties. Table~\ref{tbl:big} helps frame this view. Its rows correspond to consistency properties. We defined loop freedom and packet coherence in \S\ref{sec:loop-free}; the others are:

\paragraphb{Eventual consistency} No consistency is provided during updates. If the new set of rules computed by the controller are consistent (by any definition), the network will be eventually consistent.

\paragraphb{Drop freedom} No packet should be dropped during update. Drops may occur if a switch lacks a rule to handle a packet and, for scalability, it is not configured to send unmatched packets to the controller~\cite{swan,b4}.

%\item
%\textbf{Loop freedom} There should be no loops during updates, where we define a loop as a packet (without any transformation) visiting an (TODO: ``the same'' instead of ``an''?) interface multiple times.

%\paragraphb{Packet coherence} The set of rules seen by a packet should not be a mix of old and new rules; they should be either all old or all new rules.

\paragraphb{Memory limit} The number of rules that a switch is required to hold is always below a certain limit. A natural limit is the physical capacity of the flow table, but other limits may also be enforced.

\paragraphb{Bandwidth limit} The amount of traffic arriving at a link should not exceed a certain limit. Physical link capacity is a natural limit, but other limits may be interesting as well (e.g., margin for burstiness). That the limit be maintained without dropping traffic is implicit here; otherwise, we can trivially meet any limit.

The consistency properties we list are not the only ones of interest.
%In some applications, one may be happy with eventual consistency, the weakest consistency property possible that just guarantees that eventually, all switches will be following the new rules, and then the network is by definition consistent again.
Some networks may require different properties (e.g., balanced load across two links), and some others may require  guarantees that combine two or more properties (e.g., packet coherence + bandwidth limits). We chose these consistency properties because they are basic and natural, capturing the basic expectations of the experience of packets and network elements.

The consistency properties are listed in rough order of strength, and satisfying a property lower on the list often (but not always) satisfies a property above it. Obviously, packet coherence implies drop and loop freedom (assuming that the old and new rules sets are free of drops and loops). Perhaps less obviously, bandwidth limits imply loop freedom because flows in a loop will likely surpass any bandwidth limit.

However, these properties cannot be totally ordered. Packet coherence and bandwidth limits are orthogonal, as packet coherence does not address bandwidth, and bandwidth limits can be achieved with solutions beyond packet coherence.
Drop freedom and loop freedom are also orthogonal. In fact, trivial solutions for one violates the other---dropping packets before they enter a loop guarantees loop freedom, and just sending packets back to the sender provides drop freedom but creates loops.

%As such we established all relations between the four consistency properties we list in the table.

The columns in Table~\ref{tbl:big} denote dependency structures. They capture rules at which other switches must be updated before a new rule at a switch can be used safely. Thus, the dependency is at the rule level, not switch level; dependencies are often circular at switch level---a rule on switch $u$ depends on a rule on $v$, which in turn depends on $u$ for other rules.
Further, the dependency captures when a new rule can be installed and used safely, not when an old rule can be safely removed. Even after all new rules are being used, the rule set in the network may not be the same as the new rule set; additional (unused) rules may still exist. Such rules will be removed in a clean-up phase. The safe usage time of a new rule is important because it determines when the network is carrying traffic in the new pattern (which may have been necessitated by a failure).


% we will discuss this in \S\ref{sec:discussion}.

The different structures in Table~\ref{tbl:big} are:

\paragraphb{None} The rule does not depend on any other update.

\paragraphb{Self} The rule depends on updates at the same switch.

\paragraphb{Downstream subset} The rule depends on updates at a subset of switches that lie downstream for impacted packets.

\paragraphb{Downstream all} The rule depends on updates at all switches that lie downstream for impacted packets.

\paragraphb{Global} The rule depends on updates even at potentially all switches, including those that are not on the path for packets that use the rule.

%Some characteristics of these dependency properties are worth mentioning. First, note that the dependencies are totally ordered, i.e., no dependency is the weakest, and all is the strongest.


%\ratul{I don't get this: In other words, the dependency categories are on a qualitative level only, and do not give the same insights as a more quantitative understanding on the level of rules. In SWAN \cite{swan}, for instance, progress towards the new solution is achieved in stages, and nodes need to wait with moving to the next stage until other nodes completed the last stage. The goal is to minimize the time until we can use a new solution.}

These dependency structures are qualitative, not quantitative (e.g., time it takes for the update), but in general, update procedures with fewer dependencies (i.e., to the left) are preferable. The cells in Table~\ref{tbl:big} denote whether a procedure exists to update the network with the corresponding consistency property and dependency structure. We can prove that certain combinations are impossible
\iflongversion
(Proofs are in the Appendix.)
\else
\cite{tr}.
\fi
For example, packet coherence cannot be achieved in a way that rules depend on updates at only a subset of downstream switches.

As we can see,  weaker consistency properties (towards the top) need weaker dependency structures (towards the left). At one extreme, eventual consistency (i.e., no consistency during updates) has no dependencies at all.  Slightly stronger properties, drop freedom and memory limit, have dependencies on other rules at the switch itself. A simple procedure for drop freedom is to add the new rule in the switch before the old rule is removed. When installed with higher priority, the new rules become immediately usable, without wait.
%\ratul{should drop freedom be none? there is no dependency on other rules, in terms of when a new rule can be added and used} %not sure that we need anything here, maybe something else that goes into 5?
A simplistic method for maintaining memory limits is to remove an old rule at the same switch before adding the new rule. This method, however, may cause drops or loops.

At the other extreme, maintaining bandwidth limit requires global coordination. The intuition here is that maintaining bandwidth limits at a link requires coordinating all flows that use it, and some of these flows share links with other flows, and so on. Hong et al.~\cite{swan} describe a procedure to effect such transitions by moving flows partially across multiple stages.

Interestingly, all cells to the immediate right of impossible cells are occupied, which implies that, across past work and this paper,  (qualitatively) optimal algorithms for maintain all these consistency properties are known. However, one must not infer from this observation that finding consistent update procedures is a ``solved problem,'' for three reasons. First, some networks may need different properties, for which effective procedures or even best-case structures are unknown (e.g., load balancing across links and maintaining packet ordering within a flow).

Second, even for the properties in Table~\ref{tbl:big}, the picture looks rosy partly because the table focuses on consistency properties in isolation. The combinations are hard to  ensure, and efficient algorithms are not known. For instance, drop freedom and memory limit, while easy to ensure individually, are challenging to ensure in combination. Maintaining the combination requires global dependencies, as introducing some rule at a switch might need to remove another rule first, which can only be removed after having added a new rule somewhere else.

Third, the table only shows the qualitative part of the story, ignoring quantitative effects, which may be equally important. Even though \cite{safeupdate} and \cite{swan} both have global dependencies, \cite{safeupdate} can always resolve the dependencies in two rounds, whereas \cite{swan} may need more stages. Because of these three reasons, we believe that what is presented in this paper is just the tip of iceberg for consistent updates in SDNs.
